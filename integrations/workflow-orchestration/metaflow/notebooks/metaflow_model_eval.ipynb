{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.comet.ml/img/notebook_logo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Metaflow](https://metaflow.org/) is a human-friendly Python/R library that helps scientists and engineers build and manage real-life data science projects. Metaflow was originally developed at Netflix to boost productivity of data scientists who work on a wide variety of projects from classical statistics to state-of-the-art deep learning.\n",
    "\n",
    "[Comet](https://www.comet.ml/site/data-scientists/?utm_campaign=XXX&utm_medium=colab) is an MLOps Platform that is designed to help Data Scientists and Teams build better models faster! Comet provides tooling to track, Explain, Manage, and Monitor your models in a single place! It works with Jupyter Notebooks and Scripts and most importantly it's 100% free!\n",
    "\n",
    "To learn more about this integration, please visit \n",
    "the [Comet Documentation](https://www.comet.ml/docs/v2/integrations/ml-frameworks/metaflow/)\n",
    "\n",
    "[Find more information about our other integrations](https://www.comet.ml/docs/v2/integrations/overview/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"comet_ml>=3.31.15\" metaflow numpy torch torchvision datasets timm transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initalize Comet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "\n",
    "comet_ml.init(project_name=\"comet-example-metaflow-model-evaluation-notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a Metaflow model evaluation flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile metaflow_model_eval.py\n",
    "import json\n",
    "import os\n",
    "\n",
    "import PIL\n",
    "import timm\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from comet_ml.integration.metaflow import comet_flow\n",
    "from comet_ml.integration.pytorch import log_model\n",
    "from datasets import load_dataset\n",
    "from metaflow import FlowSpec, JSONType, Parameter, card, step\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# define custom transform function\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "\n",
    "def collate_fn(examples):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for example in examples:\n",
    "        img = transform(\n",
    "            example[\"image\"].convert(\"L\").resize((224, 224), PIL.Image.LANCZOS)\n",
    "        )\n",
    "        label = torch.tensor(example[\"label\"])\n",
    "\n",
    "        images.append(img.unsqueeze(0))\n",
    "        labels.append(label.unsqueeze(0))\n",
    "\n",
    "    images = torch.cat(images)\n",
    "    labels = torch.tensor(labels, dtype=torch.int)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def register_model(best_model, registry_name):\n",
    "    from comet_ml import API\n",
    "\n",
    "    api = API()\n",
    "\n",
    "    try:\n",
    "        existing_models = api.get_registry_model_versions(\n",
    "            workspace=os.environ[\"COMET_WORKSPACE\"], registry_name=registry_name\n",
    "        )\n",
    "        max_model_version = max(existing_models)\n",
    "\n",
    "        new_model_version = max_model_version.split(\".\")\n",
    "        new_model_version[0] = str(int(new_model_version[0]) + 1)\n",
    "        new_model_version = \".\".join(new_model_version)\n",
    "    except:\n",
    "        new_model_version = \"1.0.0\"\n",
    "\n",
    "    api_experiment = api.get_experiment_by_key(best_model[\"experiment_id\"])\n",
    "    api_experiment.register_model(\n",
    "        best_model[\"model_name\"], registry_name=registry_name, version=new_model_version\n",
    "    )\n",
    "\n",
    "\n",
    "@comet_flow(project_name=\"comet-example-metaflow-model-evaluation\")\n",
    "class ModelEvaluationFlow(FlowSpec):\n",
    "    models = Parameter(\n",
    "        \"models\",\n",
    "        help=(\"Models to evaluate\"),\n",
    "        default=[\"resnet18\", \"efficientnet_b0\"],\n",
    "    )\n",
    "    dataset_name = Parameter(\n",
    "        \"dataset_name\",\n",
    "        help=(\"Name of the dataset to use for evaluation\"),\n",
    "        default=\"imagenet_sketch\",\n",
    "    )\n",
    "    dataset_split = Parameter(\n",
    "        \"dataset_split\",\n",
    "        help=(\"Dataset Split to use for evaluation\"),\n",
    "        default=\"train\",\n",
    "    )\n",
    "    batch_size = Parameter(\n",
    "        \"batch_size\",\n",
    "        help=(\"Batch Size to Use\"),\n",
    "        default=32,\n",
    "    )\n",
    "    n_samples = Parameter(\n",
    "        \"n_samples\",\n",
    "        help=(\"Number of Samples\"),\n",
    "        default=1000,\n",
    "    )\n",
    "    seed = Parameter(\n",
    "        \"seed\",\n",
    "        help=(\"Random Seed\"),\n",
    "        default=42,\n",
    "    )\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Load the data\n",
    "        \"\"\"\n",
    "        with open(\"imagenet_labels.json\", \"rb\") as f:\n",
    "            metadata = json.load(f)\n",
    "            self.label_names = metadata[\"labels\"]\n",
    "\n",
    "        self.next(self.evaluate_classification_metrics, foreach=\"models\")\n",
    "\n",
    "    @step\n",
    "    def evaluate_classification_metrics(self):\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        dataset = load_dataset(\n",
    "            self.dataset_name, split=self.dataset_split, streaming=True\n",
    "        )\n",
    "        dataset = dataset.shuffle(self.seed, buffer_size=10_000)\n",
    "        dataset = dataset.take(self.n_samples)\n",
    "        dataset = dataset.with_format(\"torch\")\n",
    "\n",
    "        dataloader = DataLoader(\n",
    "            dataset, collate_fn=collate_fn, batch_size=self.batch_size\n",
    "        )\n",
    "\n",
    "        model = timm.create_model(self.input, pretrained=True, in_chans=1)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        self.comet_experiment.log_parameters({\"model_name\": self.input})\n",
    "\n",
    "        labels = []\n",
    "        predictions = []\n",
    "        for images, label in dataloader:\n",
    "            probs = torch.nn.functional.softmax(model(images.to(device)), dim=1)\n",
    "\n",
    "            predictions.append(probs.cpu())\n",
    "            labels.append(label)\n",
    "\n",
    "        predictions = torch.cat(predictions)\n",
    "        labels = torch.cat(labels)\n",
    "\n",
    "        clf_metrics = classification_report(\n",
    "            labels,\n",
    "            torch.argmax(predictions, dim=1),\n",
    "            labels=[i for i in range(1000)],\n",
    "            target_names=self.label_names,\n",
    "            output_dict=True,\n",
    "        )\n",
    "        accuracy = accuracy_score(labels, torch.argmax(predictions, dim=1))\n",
    "\n",
    "        self.comet_experiment.log_metrics(clf_metrics[\"micro avg\"], prefix=\"micro_avg\")\n",
    "        self.comet_experiment.log_metrics(clf_metrics[\"macro avg\"], prefix=\"macro_avg\")\n",
    "        self.comet_experiment.log_metrics({\"accuracy\": accuracy})\n",
    "\n",
    "        log_model(self.comet_experiment, model, self.input)\n",
    "\n",
    "        self.results = clf_metrics\n",
    "        self.results.update(\n",
    "            {\"model_name\": self.input, \"experiment_id\": self.comet_experiment.id}\n",
    "        )\n",
    "        self.next(self.join)\n",
    "\n",
    "    @step\n",
    "    def join(self, inputs):\n",
    "        self.results = [input.results for input in inputs]\n",
    "\n",
    "        # Find best model based on macro averaged recall\n",
    "        best_model = max(self.results, key=lambda x: x[\"macro avg\"][\"recall\"])\n",
    "\n",
    "        register_model(best_model, \"sketch-model\")\n",
    "        self.next(self.end)\n",
    "\n",
    "    @step\n",
    "    def end(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ModelEvaluationFlow()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Metaflow simple flow description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.environ.get(\"USERNAME\") is None:\n",
    "    os.environ[\"USERNAME\"] = \"googlecolab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} metaflow_model_eval.py show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Flow Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} metaflow_model_eval.py --no-pylint run --max-workers 1 --n_samples 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
