{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.comet.ml/img/notebook_logo.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Comet](https://www.comet.com/site/products/ml-experiment-tracking/?utm_campaign=keras&utm_medium=colab) is an MLOps Platform that is designed to help Data Scientists and Teams build better models faster! Comet provides tooling to track, Explain, Manage, and Monitor your models in a single place! It works with Jupyter Notebooks and Scripts and most importantly it's 100% free to get started!\n",
    "\n",
    "[Keras](https://keras.io/) is an API designed for human beings, not machines. Keras follows best practices for reducing cognitive load: it offers consistent & simple APIs, it minimizes the number of user actions required for common use cases, and it provides clear & actionable error messages. It also has extensive documentation and developer guides.\n",
    "\n",
    "Instrument Keras with Comet to start managing experiments, create dataset versions and track hyperparameters for faster and easier reproducibility and collaboration.\n",
    "\n",
    "[Find more information about our integration with Keras](https://www.comet.ml/docs/v2/integrations/ml-frameworks/keras/)\n",
    "\n",
    "Get a preview for what's to come. Check out a completed experiment created from this notebook [here](https://www.comet.com/examples/comet-example-keras-notebook/ef20812c7b1d4876a7cbd5679a12c309).\n",
    "\n",
    "This example is based on the [following Keras MNist example](https://keras.io/examples/vision/mnist_convnet/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYchV5RWwdv5"
   },
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJnmqphuY2eI"
   },
   "outputs": [],
   "source": [
    "%pip install comet_ml tensorflow numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crOcPHobwhGL"
   },
   "source": [
    "# Initialize Comet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNQRM0U3caiY"
   },
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "\n",
    "comet_ml.init(project_name=\"comet-example-keras-notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgqwGSwtzVWD"
   },
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-5rRYaUw5AF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3T8Qg7GYwwM2"
   },
   "source": [
    "# Create a Comet Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-OWU2ynwp2u"
   },
   "outputs": [],
   "source": [
    "experiment = comet_ml.Experiment(\n",
    "    auto_histogram_weight_logging=True,\n",
    "    auto_histogram_gradient_logging=True,\n",
    "    auto_histogram_activation_logging=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 3,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"categorical_crossentropy\",\n",
    "    \"validation_split\": 0.1,\n",
    "}\n",
    "\n",
    "experiment.log_parameters(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJuThf1TxP_G"
   },
   "source": [
    "# Load and prepare the dataset\n",
    "\n",
    "We are using tensorflow datasets library to download the dataset for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFbozHiJxTax"
   },
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=parameters[\"loss\"], optimizer=parameters[\"optimizer\"], metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=parameters[\"batch_size\"],\n",
    "    epochs=parameters[\"epochs\"],\n",
    "    validation_split=parameters[\"validation_split\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the trained model\n",
    "\n",
    "It is now time to test the trained model against the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End experiment\n",
    "\n",
    "This will logs the notebook code and make sure that all the data has been sent to Comet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
