{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mc4eSX588bM"
   },
   "source": [
    "<img src=\"https://cdn.comet.ml/img/notebook_logo.png\">\n",
    "\n",
    "# Anomalib + Comet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fX8WQU4VCFbP"
   },
   "source": [
    "## ⚙ **Step 0:** Setup and Installation\n",
    "Clone the Anomalib project into your environment and install the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install comet_ml --q\n",
    "import comet_ml"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfJ7ria2WgZb",
    "outputId": "99f83301-9086-4c07-badb-471f64ee4663"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m501.8/501.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Dr3VHzafL-z",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "11e06f48-7d32-46fa-837d-7dec04097e08"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'anomalib'...\n",
      "remote: Enumerating objects: 28365, done.\u001b[K\n",
      "remote: Counting objects: 100% (292/292), done.\u001b[K\n",
      "remote: Compressing objects: 100% (227/227), done.\u001b[K\n",
      "remote: Total 28365 (delta 98), reused 194 (delta 57), pack-reused 28073\u001b[K\n",
      "Receiving objects: 100% (28365/28365), 1.50 GiB | 31.26 MiB/s, done.\n",
      "Resolving deltas: 100% (15667/15667), done.\n",
      "/content/anomalib\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m569.1/569.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.7/529.7 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.4/190.4 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m551.6/551.6 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for anomalib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for freia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/openvinotoolkit/anomalib.git\n",
    "%cd anomalib\n",
    "!pip install . --q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuIgS50s9FTh"
   },
   "source": [
    "## ⚙ **Step 1:** Configure Comet Credentials\n",
    "\n",
    "If you don't already have a Comet account, you can sign up for free [here](https://www.comet.com/signup?utm_source=colab&utm_medium=referral&utm_campaign=AMS_US_EN_AWA_Online_Anomalib_Comet_Integration). Make sure to grab your API key from your account settings and configure your Comet credentials in [any of several ways](https://www.comet.com/docs/v2/guides/tracking-ml-training/configuring-comet/).\n",
    "\n",
    "For interactive environments like Colab or Jupyter notebooks, the easiest way to do so is often by using the following command. Note that the project parameter is optional, and will default to the name of the dataset used.\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "comet_ml.init(api_key=\"<YOUR-COMET-API-KEY-HERE>\")"
   ],
   "metadata": {
    "id": "jbmCLpu6T8P7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c65cb2d4-4c41-4b3e-9b3b-30934dfa5452"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqJ_ZWfWI36v"
   },
   "source": [
    "## ⚙ **Step 2:** Modify the Anomalib config file\n",
    "Next, we'll need to modify our Anomalib config file to enable logging. The easiest way to do this is to open `anomalib/anomalib/models/<model-of-your-choice>/config.yaml` and adjust the relevant parameters accordingly. For our purposes, we only need to adjust the following lines:\n",
    "\n",
    "```\n",
    "visualization:\n",
    "  show_images: true\n",
    "  save_images: true\n",
    "  log_images: true\n",
    "  mode: full # options: [\"full\", \"simple\"]\n",
    "\n",
    " logging:\n",
    "  logger: comet\n",
    "  log_graph: true\n",
    "```\n",
    "\n",
    "If you'd rather keep the default config template and create a second, customized version, we've written a `yaml` file below to use with the FastFlow model on the MVTec dataset. Feel free to use and modify this code for your particular use case, but be aware that **each model has a different config file structure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqEjiNtfhD0w"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "config_file = {\n",
    "    \"dataset\": {\n",
    "        \"name\": \"mvtec\",\n",
    "        \"format\": \"mvtec\",\n",
    "        \"path\": \"./data/MVTec\",\n",
    "        \"task\": \"segmentation\",\n",
    "        \"category\": \"bottle\",\n",
    "        \"image_size\": 256,\n",
    "        \"train_batch_size\": 32,\n",
    "        \"test_batch_size\": 32,\n",
    "        \"num_workers\": 8,\n",
    "        \"normalization\": \"imagenet\",\n",
    "        \"test_split_mode\": \"from_dir\",\n",
    "        \"test_split_ratio\": 0.2,\n",
    "        \"val_split_mode\": \"same_as_test\",\n",
    "        \"val_split_ratio\": 0.5,\n",
    "        \"transform_config\": {\"train\": None, \"val\": None},\n",
    "        \"create_validation_set\": False,\n",
    "        \"tiling\": {\n",
    "            \"apply\": False,\n",
    "            \"tile_size\": None,\n",
    "            \"stride\": None,\n",
    "            \"remove_border_count\": 0,\n",
    "            \"use_random_tiling\": False,\n",
    "            \"random_til_count\": 16,\n",
    "        },\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"name\": \"fastflow\",\n",
    "        \"backbone\": \"resnet18\",\n",
    "        \"pre_trained\": True,\n",
    "        \"flow_steps\": 8,\n",
    "        \"hidden_ratio\": 1.0,\n",
    "        \"conv3x3_only\": True,\n",
    "        \"lr\": 0.001,\n",
    "        \"weight_decay\": 0.00001,\n",
    "        \"early_stopping\": {\n",
    "            \"patience\": 3,\n",
    "            \"metric\": \"pixel_AUROC\",\n",
    "            \"mode\": \"max\",\n",
    "        },\n",
    "        \"normalization_method\": \"min_max\",\n",
    "    },\n",
    "    \"metrics\": {\n",
    "        \"image\": [\"F1Score\", \"AUROC\"],\n",
    "        \"pixel\": [\"F1Score\", \"AUROC\"],\n",
    "        \"threshold\": {\"image_default\": 0, \"pixel_default\": 0, \"adaptive\": True},\n",
    "    },\n",
    "    \"visualization\": {\n",
    "        \"show_images\": False,\n",
    "        \"save_images\": True,\n",
    "        \"log_images\": True,\n",
    "        \"image_save_path\": None,\n",
    "        \"mode\": \"full\",\n",
    "    },\n",
    "    \"project\": {\"seed\": 42, \"path\": \"./results\"},\n",
    "    \"logging\": {\"logger\": \"comet\", \"log_graph\": True},\n",
    "    \"optimization\": {\"export_mode\": None},\n",
    "    \"trainer\": {\n",
    "        \"accelerator\": \"auto\",\n",
    "        \"accumulate_grad_batches\": 1,\n",
    "        \"amp_backend\": \"native\",\n",
    "        \"auto_lr_find\": False,\n",
    "        \"auto_select_gpus\": False,\n",
    "        \"benchmark\": False,\n",
    "        \"check_val_every_n_epoch\": 1,\n",
    "        \"default_root_dir\": None,\n",
    "        \"detect_anomaly\": False,\n",
    "        \"deterministic\": False,\n",
    "        \"devices\": 1,\n",
    "        \"enable_checkpointing\": True,\n",
    "        \"enable_model_summary\": True,\n",
    "        \"enable_progress_bar\": True,\n",
    "        \"fast_dev_run\": False,\n",
    "        \"gpus\": None,\n",
    "        \"gradient_clip_val\": 0,\n",
    "        \"ipus\": None,\n",
    "        \"limit_predict_batches\": 1.0,\n",
    "        \"limit_test_batches\": 1.0,\n",
    "        \"limit_train_batches\": 1.0,\n",
    "        \"limit_val_batches\": 1.0,\n",
    "        \"log_every_n_steps\": 50,\n",
    "        \"max_epochs\": 500,\n",
    "        \"max_steps\": -1,\n",
    "        \"max_time\": None,\n",
    "        \"min_epochs\": None,\n",
    "        \"min_steps\": None,\n",
    "        \"move_metrics_to_cpu\": False,\n",
    "        \"multiple_trainloader_mode\": \"max_size_cycle\",\n",
    "        \"num_nodes\": 1,\n",
    "        \"num_processes\": None,\n",
    "        \"num_sanity_val_steps\": 0,\n",
    "        \"overfit_batches\": 0.0,\n",
    "        \"plugins\": None,\n",
    "        \"precision\": 32,\n",
    "        \"profiler\": None,\n",
    "        \"reload_dataloaders_every_n_epochs\": 0,\n",
    "        \"replace_sampler_ddp\": True,\n",
    "        \"strategy\": None,\n",
    "        \"sync_batchnorm\": False,\n",
    "        \"tpu_cores\": None,\n",
    "        \"track_grad_norm\": -1,\n",
    "        \"val_check_interval\": 1.0,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "#%cd anomalib/models/fastflow\n",
    "with open(r\"src/anomalib/models/fastflow/custom_config.yaml\", \"w\") as file:\n",
    "    documents = yaml.dump(config_file, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxtL8el8I3wX"
   },
   "source": [
    "## ⚙ **Step 3:** Training\n",
    "By default `!python tools/train.py` runs the PaDiM model on the bottle category from the MVTec AD (CC BY-NC-SA 4.0) dataset.\n",
    "\n",
    "To use a different algorithm, just switch out the model name in the config file path to another supported algorithm. To use a custom dataset, just update the relevant Anomalib config file accordingly with the path to your dataset.\n",
    "\n",
    "```\n",
    "!python tools/train.py --config src/anomalib/models/<specific-model-name>/<config-file>.yaml\n",
    "```\n",
    "\n",
    "Alternatively, if we pass a model name to the `--model` flag, the script will automatically find our config file (so long as it is stored in the appropriate folder as `config.yaml`).\n",
    "\n",
    "```\n",
    "!python tools/train.py --model <specific-model-name>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CezXI1d848cg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b0b0005f-b0ae-4017-ccc7-efaaed6ca8ce"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "To use wandb logger install it using `pip install wandb`\n",
      "/usr/local/lib/python3.10/dist-packages/anomalib/config/config.py:275: UserWarning: config.project.unique_dir is set to False. This does not ensure that your results will be written in an empty directory and you may overwrite files.\n",
      "  warn(\n",
      "Global seed set to 42\n",
      "2023-04-28 14:56:57,557 - anomalib.data - INFO - Loading the datamodule\n",
      "2023-04-28 14:56:57,558 - anomalib.data.utils.transform - INFO - No config file has been provided. Using default transforms.\n",
      "2023-04-28 14:56:57,558 - anomalib.data.utils.transform - INFO - No config file has been provided. Using default transforms.\n",
      "2023-04-28 14:56:57,558 - anomalib.models - INFO - Loading the model.\n",
      "2023-04-28 14:56:57,559 - anomalib.models.components.base.anomaly_module - INFO - Initializing FastflowLightning model.\n",
      "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "2023-04-28 14:56:57,747 - timm.models.helpers - INFO - Loading pretrained weights from url (https://download.pytorch.org/models/resnet18-5c106cde.pth)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n",
      "2023-04-28 14:56:58,684 - anomalib.utils.loggers - INFO - Loading the experiment logger(s)\n",
      "2023-04-28 14:56:58,685 - pytorch_lightning.loggers.comet - INFO - CometLogger will be initialized in online mode\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com \u001b[38;5;39mhttps://www.comet.com/anmorgan24/mvtec/4daeef6254f3457fa856a461a3305b69\u001b[0m\n",
      "\n",
      "2023-04-28 14:56:59,670 - anomalib.utils.callbacks - INFO - Loading the callbacks\n",
      "/usr/local/lib/python3.10/dist-packages/anomalib/utils/callbacks/__init__.py:142: UserWarning: Export option: None not found. Defaulting to no model export\n",
      "  warnings.warn(f\"Export option: {config.optimization.export_mode} not found. Defaulting to no model export\")\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:406: LightningDeprecationWarning: The NVIDIA/apex AMP implementation has been deprecated upstream. Consequently, its integration inside PyTorch Lightning has been deprecated in v1.9.0 and will be removed in v2.0.0. The `Trainer(amp_backend='native')` argument is deprecated. Removing this argument will avoid this message, it will select PyTorch's implementation automatically.\n",
      "  rank_zero_deprecation(\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "  rank_zero_deprecation(\n",
      "2023-04-28 14:56:59,741 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: True (cuda), used: True\n",
      "2023-04-28 14:56:59,741 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores\n",
      "2023-04-28 14:56:59,741 - pytorch_lightning.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs\n",
      "2023-04-28 14:56:59,741 - pytorch_lightning.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs\n",
      "2023-04-28 14:56:59,742 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "2023-04-28 14:56:59,743 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "2023-04-28 14:56:59,743 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "2023-04-28 14:56:59,743 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(limit_predict_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "2023-04-28 14:56:59,744 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "2023-04-28 14:56:59,744 - anomalib - INFO - Training the model.\n",
      "2023-04-28 14:56:59,971 - anomalib.data.utils.download - INFO - Downloading the mvtec dataset.\n",
      "mvtec: 5.26GB [05:22, 16.3MB/s]                            \n",
      "2023-04-28 15:02:22,169 - anomalib.data.utils.download - INFO - Checking the hash of the downloaded file.\n",
      "2023-04-28 15:02:37,403 - anomalib.data.utils.download - INFO - Extracting dataset into root folder.\n",
      "2023-04-28 15:04:04,334 - anomalib.data.utils.download - INFO - Cleaning up files.\n",
      "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "2023-04-28 15:04:05,557 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2023-04-28 15:04:05,567 - pytorch_lightning.callbacks.model_summary - INFO - \n",
      "  | Name                  | Type                     | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | image_threshold       | AnomalyScoreThreshold    | 0     \n",
      "1 | pixel_threshold       | AnomalyScoreThreshold    | 0     \n",
      "2 | model                 | FastflowModel            | 9.7 M \n",
      "3 | loss                  | FastflowLoss             | 0     \n",
      "4 | image_metrics         | AnomalibMetricCollection | 0     \n",
      "5 | pixel_metrics         | AnomalibMetricCollection | 0     \n",
      "6 | normalization_metrics | MinMax                   | 0     \n",
      "-------------------------------------------------------------------\n",
      "5.6 M     Trainable params\n",
      "4.2 M     Non-trainable params\n",
      "9.7 M     Total params\n",
      "38.936    Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Epoch 0:   0%|          | 0/10 [00:00<?, ?it/s] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:83: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:83: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 17. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 10/10 [00:14<00:00,  1.41s/it, loss=1.44e+05, v_num=5b69, train_loss_step=7.26e+4, pixel_F1Score=0.484, pixel_AUROC=0.866]\n",
      "Epoch 1:   0%|          | 0/10 [00:00<?, ?it/s, loss=1.44e+05, v_num=5b69, train_loss_step=7.26e+4, pixel_F1Score=0.484, pixel_AUROC=0.866, train_loss_epoch=1.49e+5]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 10/10 [00:12<00:00,  1.22s/it, loss=6.8e+04, v_num=5b69, train_loss_step=-6.21e+4, pixel_F1Score=0.610, pixel_AUROC=0.944, train_loss_epoch=1.49e+5]\n",
      "Epoch 2:   0%|          | 0/10 [00:00<?, ?it/s, loss=6.8e+04, v_num=5b69, train_loss_step=-6.21e+4, pixel_F1Score=0.610, pixel_AUROC=0.944, train_loss_epoch=-4.11e+3]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:   0%|          | 0/10 [00:00<?, ?it/s, loss=-2e+03, v_num=5b69, train_loss_step=-1.5e+5, pixel_F1Score=0.632, pixel_AUROC=0.958, train_loss_epoch=-1.05e+5]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 10/10 [00:12<00:00,  1.23s/it, loss=-1.09e+05, v_num=5b69, train_loss_step=-2.18e+5, pixel_F1Score=0.652, pixel_AUROC=0.968, train_loss_epoch=-1.05e+5]\n",
      "Epoch 4:   0%|          | 0/10 [00:00<?, ?it/s, loss=-1.09e+05, v_num=5b69, train_loss_step=-2.18e+5, pixel_F1Score=0.652, pixel_AUROC=0.968, train_loss_epoch=-1.85e+5]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 10/10 [00:12<00:00,  1.22s/it, loss=-1.88e+05, v_num=5b69, train_loss_step=-2.74e+5, pixel_F1Score=0.665, pixel_AUROC=0.972, train_loss_epoch=-1.85e+5]\n",
      "Epoch 5:   0%|          | 0/10 [00:00<?, ?it/s, loss=-1.88e+05, v_num=5b69, train_loss_step=-2.74e+5, pixel_F1Score=0.665, pixel_AUROC=0.972, train_loss_epoch=-2.49e+5]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 10/10 [00:11<00:00,  1.16s/it, loss=-2.48e+05, v_num=5b69, train_loss_step=-3.14e+5, pixel_F1Score=0.689, pixel_AUROC=0.977, train_loss_epoch=-2.49e+5]\n",
      "Epoch 6:   0%|          | 0/10 [00:00<?, ?it/s, loss=-2.48e+05, v_num=5b69, train_loss_step=-3.14e+5, pixel_F1Score=0.689, pixel_AUROC=0.977, train_loss_epoch=-2.93e+5]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 10/10 [00:11<00:00,  1.11s/it, loss=-3.02e+05, v_num=5b69, train_loss_step=-3.67e+5, pixel_F1Score=0.690, pixel_AUROC=0.977, train_loss_epoch=-2.93e+5]\n",
      "Epoch 7:   0%|          | 0/10 [00:00<?, ?it/s, loss=-3.02e+05, v_num=5b69, train_loss_step=-3.67e+5, pixel_F1Score=0.690, pixel_AUROC=0.977, train_loss_epoch=-3.48e+5]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 10/10 [00:12<00:00,  1.26s/it, loss=-3.49e+05, v_num=5b69, train_loss_step=-4.15e+5, pixel_F1Score=0.683, pixel_AUROC=0.978, train_loss_epoch=-3.48e+5]\n",
      "Epoch 8:   0%|          | 0/10 [00:00<?, ?it/s, loss=-3.49e+05, v_num=5b69, train_loss_step=-4.15e+5, pixel_F1Score=0.683, pixel_AUROC=0.978, train_loss_epoch=-3.91e+5]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 10/10 [00:11<00:00,  1.18s/it, loss=-3.92e+05, v_num=5b69, train_loss_step=-4.31e+5, pixel_F1Score=0.689, pixel_AUROC=0.978, train_loss_epoch=-3.91e+5]\n",
      "Epoch 9:   0%|          | 0/10 [00:00<?, ?it/s, loss=-3.92e+05, v_num=5b69, train_loss_step=-4.31e+5, pixel_F1Score=0.689, pixel_AUROC=0.978, train_loss_epoch=-4.24e+5]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it, loss=-4.28e+05, v_num=5b69, train_loss_step=-4.77e+5, pixel_F1Score=0.691, pixel_AUROC=0.978, train_loss_epoch=-4.24e+5]\n",
      "Epoch 10:   0%|          | 0/10 [00:00<?, ?it/s, loss=-4.28e+05, v_num=5b69, train_loss_step=-4.77e+5, pixel_F1Score=0.691, pixel_AUROC=0.978, train_loss_epoch=-4.57e+5]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 10/10 [00:11<00:00,  1.18s/it, loss=-4.57e+05, v_num=5b69, train_loss_step=-4.71e+5, pixel_F1Score=0.696, pixel_AUROC=0.980, train_loss_epoch=-4.57e+5]\n",
      "Epoch 11:   0%|          | 0/10 [00:00<?, ?it/s, loss=-4.57e+05, v_num=5b69, train_loss_step=-4.71e+5, pixel_F1Score=0.696, pixel_AUROC=0.980, train_loss_epoch=-4.83e+5]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 10/10 [00:11<00:00,  1.19s/it, loss=-4.84e+05, v_num=5b69, train_loss_step=-5.15e+5, pixel_F1Score=0.696, pixel_AUROC=0.979, train_loss_epoch=-4.83e+5]\n",
      "Epoch 12:   0%|          | 0/10 [00:00<?, ?it/s, loss=-4.84e+05, v_num=5b69, train_loss_step=-5.15e+5, pixel_F1Score=0.696, pixel_AUROC=0.979, train_loss_epoch=-5.04e+5]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 10/10 [00:12<00:00,  1.21s/it, loss=-5.11e+05, v_num=5b69, train_loss_step=-5.56e+5, pixel_F1Score=0.684, pixel_AUROC=0.978, train_loss_epoch=-5.04e+5]\n",
      "Epoch 13:   0%|          | 0/10 [00:00<?, ?it/s, loss=-5.11e+05, v_num=5b69, train_loss_step=-5.56e+5, pixel_F1Score=0.684, pixel_AUROC=0.978, train_loss_epoch=-5.41e+5]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it, loss=-5.4e+05, v_num=5b69, train_loss_step=-5.72e+5, pixel_F1Score=0.685, pixel_AUROC=0.978, train_loss_epoch=-5.41e+5] \n",
      "Epoch 13: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it, loss=-5.4e+05, v_num=5b69, train_loss_step=-5.72e+5, pixel_F1Score=0.685, pixel_AUROC=0.978, train_loss_epoch=-5.66e+5]\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Set model graph ignored; already called. Call with overwrite=True to replace graph definition\n",
      "Epoch 13: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it, loss=-5.4e+05, v_num=5b69, train_loss_step=-5.72e+5, pixel_F1Score=0.685, pixel_AUROC=0.978, train_loss_epoch=-5.66e+5]\n",
      "2023-04-28 15:06:56,766 - anomalib.utils.callbacks.timer - INFO - Training took 171.21 seconds\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : \u001b[38;5;39mhttps://www.comet.com/anmorgan24/mvtec/4daeef6254f3457fa856a461a3305b69\u001b[0m\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     image_AUROC [14]      : (0.9285714626312256, 1.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     image_F1Score [14]    : (0.9172931909561157, 1.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pixel_AUROC [14]      : (0.8664562702178955, 0.9801030158996582)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pixel_F1Score [14]    : (0.48442572355270386, 0.6961222290992737)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_epoch [14] : (-566332.125, 149180.3125)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_step       : -371852.96875\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Created from : Anomalib\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name         : bottle fastflow\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/category                          : bottle\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/create_validation_set             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/eval_batch_size                   : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/format                            : mvtec\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/image_size                        : [256, 256]\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/name                              : mvtec\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/normalization                     : imagenet\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/num_workers                       : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/path                              : ./data/MVTec\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/task                              : segmentation\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/test_batch_size                   : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/test_split_mode                   : from_dir\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/test_split_ratio                  : 0.2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/tiling/apply                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/tiling/random_til_count           : 16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/tiling/remove_border_count        : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/tiling/stride                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/tiling/tile_size                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/tiling/use_random_tiling          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/train_batch_size                  : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/transform_config/eval             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/transform_config/train            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/transform_config/val              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/val_split_mode                    : same_as_test\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/val_split_ratio                   : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     logging/log_graph                         : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     logging/logger                            : comet\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/image                             : ['F1Score', 'AUROC']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/pixel                             : ['F1Score', 'AUROC']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/threshold/adaptive                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/threshold/image_default           : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/threshold/manual_image            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/threshold/manual_pixel            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/threshold/method                  : adaptive\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/threshold/pixel_default           : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/backbone                            : resnet18\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/conv3x3_only                        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/early_stopping/metric               : pixel_AUROC\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/early_stopping/mode                 : max\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/early_stopping/patience             : 3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/flow_steps                          : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/hidden_ratio                        : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/input_size                          : [256, 256]\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/lr                                  : 0.001\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/name                                : fastflow\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/normalization_method                : min_max\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/pre_trained                         : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/weight_decay                        : 1e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimization/export_mode                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project/path                              : results/fastflow/mvtec/bottle/run\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project/seed                              : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project/unique_dir                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/accelerator                       : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/accumulate_grad_batches           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/amp_backend                       : native\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/auto_lr_find                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/auto_select_gpus                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/benchmark                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/check_val_every_n_epoch           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/default_root_dir                  : results/fastflow/mvtec/bottle/run\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/detect_anomaly                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/deterministic                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/devices                           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/enable_checkpointing              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/enable_model_summary              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/enable_progress_bar               : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/fast_dev_run                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/gpus                              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/gradient_clip_val                 : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/ipus                              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/limit_predict_batches             : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/limit_test_batches                : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/limit_train_batches               : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/limit_val_batches                 : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/log_every_n_steps                 : 50\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/max_epochs                        : 500\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/max_steps                         : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/max_time                          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/min_epochs                        : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/min_steps                         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/move_metrics_to_cpu               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/multiple_trainloader_mode         : max_size_cycle\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/num_nodes                         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/num_processes                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/num_sanity_val_steps              : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/overfit_batches                   : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/plugins                           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/precision                         : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/profiler                          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/reload_dataloaders_every_n_epochs : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/replace_sampler_ddp               : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/strategy                          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/sync_batchnorm                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/tpu_cores                         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/track_grad_norm                   : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/val_check_interval                : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualization/image_save_path             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualization/log_images                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualization/mode                        : full\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualization/save_images                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualization/show_images                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (225 bytes)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 2 (6.98 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "2023-04-28 15:06:59,186 - anomalib - INFO - Loading the best model weights.\n",
      "2023-04-28 15:06:59,186 - anomalib - INFO - Testing the model.\n",
      "2023-04-28 15:06:59,222 - pytorch_lightning.utilities.rank_zero - INFO - The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: EarlyStopping\n",
      "2023-04-28 15:06:59,223 - anomalib.data.mvtec - INFO - Found the dataset.\n",
      "2023-04-28 15:06:59,223 - anomalib.utils.callbacks.model_loader - INFO - Loading the model from /content/anomalib/results/fastflow/mvtec/bottle/run/weights/lightning/model.ckpt\n",
      "2023-04-28 15:06:59,416 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com \u001b[38;5;39mhttps://www.comet.com/anmorgan24/mvtec/4daeef6254f3457fa856a461a3305b69\u001b[0m\n",
      "\n",
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:36<00:00, 12.13s/it]2023-04-28 15:07:38,744 - anomalib.utils.callbacks.timer - INFO - Testing took 38.555514335632324 seconds\n",
      "Throughput (batch_size=32) : 2.1527400536657573 FPS\n",
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:37<00:00, 12.36s/it]\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9976190328598022    \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9921259880065918    \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9801030158996582    \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6961222290992737    \u001b[0m\u001b[35m \u001b[0m│\n",
      "└───────────────────────────┴───────────────────────────┘\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml ExistingExperiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : \u001b[38;5;39mhttps://www.comet.com/anmorgan24/mvtec/4daeef6254f3457fa856a461a3305b69\u001b[0m\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     image_AUROC   : 0.9976190328598022\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     image_F1Score : 0.9921259880065918\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pixel_AUROC   : 0.9801030158996582\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pixel_F1Score : 0.6961222290992737\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Created from : pytorch-lightning\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name         : bottle fastflow\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/category                          : bottle\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/create_validation_set             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/eval_batch_size                   : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/format                            : mvtec\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/image_size                        : [256, 256]\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/name                              : mvtec\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/normalization                     : imagenet\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/num_workers                       : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/path                              : ./data/MVTec\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/task                              : segmentation\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/test_batch_size                   : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/test_split_mode                   : from_dir\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/test_split_ratio                  : 0.2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/tiling/apply                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/tiling/random_til_count           : 16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/tiling/remove_border_count        : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/tiling/stride                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/tiling/tile_size                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/tiling/use_random_tiling          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/train_batch_size                  : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/transform_config/eval             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/transform_config/train            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/transform_config/val              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/val_split_mode                    : same_as_test\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset/val_split_ratio                   : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     logging/log_graph                         : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     logging/logger                            : comet\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/image                             : ['F1Score', 'AUROC']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/pixel                             : ['F1Score', 'AUROC']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/threshold/adaptive                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/threshold/image_default           : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/threshold/manual_image            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/threshold/manual_pixel            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/threshold/method                  : adaptive\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/threshold/pixel_default           : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/backbone                            : resnet18\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/conv3x3_only                        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/early_stopping/metric               : pixel_AUROC\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/early_stopping/mode                 : max\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/early_stopping/patience             : 3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/flow_steps                          : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/hidden_ratio                        : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/input_size                          : [256, 256]\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/lr                                  : 0.001\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/name                                : fastflow\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/normalization_method                : min_max\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/pre_trained                         : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/weight_decay                        : 1e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimization/export_mode                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project/path                              : results/fastflow/mvtec/bottle/run\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project/seed                              : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project/unique_dir                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/accelerator                       : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/accumulate_grad_batches           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/amp_backend                       : native\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/auto_lr_find                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/auto_select_gpus                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/benchmark                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/check_val_every_n_epoch           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/default_root_dir                  : results/fastflow/mvtec/bottle/run\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/detect_anomaly                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/deterministic                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/devices                           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/enable_checkpointing              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/enable_model_summary              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/enable_progress_bar               : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/fast_dev_run                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/gpus                              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/gradient_clip_val                 : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/ipus                              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/limit_predict_batches             : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/limit_test_batches                : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/limit_train_batches               : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/limit_val_batches                 : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/log_every_n_steps                 : 50\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/max_epochs                        : 500\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/max_steps                         : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/max_time                          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/min_epochs                        : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/min_steps                         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/move_metrics_to_cpu               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/multiple_trainloader_mode         : max_size_cycle\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/num_nodes                         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/num_processes                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/num_sanity_val_steps              : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/overfit_batches                   : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/plugins                           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/precision                         : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/profiler                          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/reload_dataloaders_every_n_epochs : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/replace_sampler_ddp               : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/strategy                          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/sync_batchnorm                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/tpu_cores                         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/track_grad_norm                   : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer/val_check_interval                : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualization/image_save_path             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualization/log_images                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualization/mode                        : full\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualization/save_images                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualization/show_images                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     figures     : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images      : 83\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 1 metrics, params and output messages\n"
     ]
    }
   ],
   "source": [
    "!python tools/train.py --config src/anomalib/models/fastflow/custom_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtAbrSMQX_jM"
   },
   "source": [
    "Now just head on over to the Comet UI to see your results!\n",
    "\n",
    "[![anomalib-colab-panels.gif](https://s4.gifyu.com/images/anomalib-colab-panels.gif)](https://www.comet.com/site/)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}