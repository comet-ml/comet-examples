{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/7529846/230328046-a8b18c51-12e3-4617-9b39-97614a571a2d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this guide we will demonstrate how to track your Langchain Experiments, Evaluation Metrics, and LLM Sessions with [Comet](https://www.comet.com/site/?utm_source=langchain&utm_medium=referral&utm_campaign=comet_notebook).  \n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/hwchase17/langchain/blob/master/docs/ecosystem/comet_tracking.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "**Example Project:** [Comet with LangChain](https://www.comet.com/lothiraldan/langchain-integration-beta/prompts?utm_source=langchain&utm_medium=referral&utm_campaign=comet_notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"1280\" alt=\"comet-langchain\" src=\"https://user-images.githubusercontent.com/7529846/230326720-a9711435-9c6f-4edb-a707-94b67271ab25.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Comet and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U comet_llm \"langchain>=0.0.162\" openai google-search-results spacy textstat pandas\n",
    "\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Comet and Set your Credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can grab your [Comet API Key here](https://www.comet.com/signup?utm_source=langchain&utm_medium=referral&utm_campaign=comet_notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import comet_llm\n",
    "\n",
    "# os.environ['COMET_API_KEY'] = YOUR-COMET-API-KEY\n",
    "# os.environ['COMET_PROJECT_NAME'] = YOUR-PROJECT-NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set OpenAI and SerpAPI credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need an [OpenAI API Key](https://platform.openai.com/account/api-keys) and a [SerpAPI API Key](https://serpapi.com/dashboard) to run the following examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "# os.environ[\"OPENAI_ORGANIZATION\"] = \"...\"\n",
    "# os.environ[\"SERPAPI_API_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the beta-version of the Langchain callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.tracers.base import BaseTracer\n",
    "\n",
    "\n",
    "def get_run_type(run):\n",
    "    if isinstance(run.run_type, str):\n",
    "        return run.run_type\n",
    "    elif hasattr(run.run_type, \"value\"):\n",
    "        return run.run_type.value\n",
    "    else:\n",
    "        return str(run.run_type)\n",
    "\n",
    "\n",
    "class CometTracer(BaseTracer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.span_map = {}\n",
    "\n",
    "    def _persist_run(self, run) -> None:\n",
    "        comet_llm.end_chain(outputs=run.outputs)\n",
    "\n",
    "    def _start_trace(self, run) -> None:\n",
    "        if not run.parent_run_id:\n",
    "            # This is the first run, which maps to a chain\n",
    "            comet_llm.start_chain(inputs=run.inputs)\n",
    "        else:\n",
    "            span = comet_llm.Span(\n",
    "                inputs=run.inputs,\n",
    "                category=get_run_type(run),\n",
    "                metadata=run.extra,\n",
    "                name=run.name,\n",
    "            ).__enter__()\n",
    "            self.span_map[run.id] = span\n",
    "        super()._start_trace(run)\n",
    "\n",
    "    def _end_trace(self, run) -> None:\n",
    "        if not run.parent_run_id:\n",
    "            pass\n",
    "            # Langchain will call _persist_run for us\n",
    "        else:\n",
    "            span = self.span_map[run.id]\n",
    "            span.set_outputs(outputs=run.outputs)\n",
    "            span.__exit__(None, None, None)\n",
    "        super()._end_trace(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: Using just an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "comet_tracer = CometTracer()\n",
    "callbacks = [comet_tracer]\n",
    "llm = OpenAI(temperature=0.9, callbacks=callbacks, verbose=True)\n",
    "\n",
    "for prompt in [\"Tell me a joke\", \"Tell me a poem\", \"Tell me a fact\"]:\n",
    "    llm_result = llm.generate([prompt], callbacks=[comet_tracer])\n",
    "    print(\"LLM result\", llm_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: Using an LLM in a Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "tracer = CometTracer()\n",
    "callbacks = [tracer]\n",
    "\n",
    "llm = OpenAI(temperature=0.9, callbacks=callbacks, verbose=True)\n",
    "\n",
    "template = \"\"\"You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\n",
    "Title: {title}\n",
    "Playwright: This is a synopsis for the above play:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"title\"], template=template)\n",
    "synopsis_chain = LLMChain(\n",
    "    llm=llm, prompt=prompt_template, callbacks=callbacks, verbose=True\n",
    ")\n",
    "\n",
    "test_prompts = [{\"title\": \"Documentary about Bigfoot in Paris\"}]\n",
    "print(synopsis_chain.apply(test_prompts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3: Using An Agent with Tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "\n",
    "tracer = CometTracer()\n",
    "callbacks = [tracer]\n",
    "\n",
    "llm = OpenAI(temperature=0.9, callbacks=callbacks, verbose=True)\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm, callbacks=callbacks, verbose=True)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    callbacks=callbacks,\n",
    "    verbose=True,\n",
    ")\n",
    "agent.run(\n",
    "    \"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\",\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
