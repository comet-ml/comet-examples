{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ot2sn7Zrzwtt"
   },
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6Zdp2mOu2Xb"
   },
   "outputs": [],
   "source": [
    "%pip install -U \"comet_ml>=3.44.0\" mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4aji9dozzbe"
   },
   "source": [
    "# Login to Comet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTae69M2u-hl"
   },
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "\n",
    "comet_ml.login(project_name=\"comet-example-mlflow-notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1R-zIOmm2gJP"
   },
   "source": [
    "# Run MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-a86wIo3mfj"
   },
   "source": [
    "Once Comet is imported at the top of your script, it will automatically log experiment data from your MLFlow runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljuZ8I_q2ZgX"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# The following import and function call are the only additions to code required\n",
    "# to automatically log metrics and parameters to MLflow.\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "import numpy as np\n",
    "from keras.datasets import reuters\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# The sqlite store is needed for the model registry\n",
    "mlflow.set_tracking_uri(\"sqlite:///db.sqlite\")\n",
    "\n",
    "# We need to create a run before calling keras or MLFlow will end the run by itself\n",
    "mlflow.start_run()\n",
    "\n",
    "mlflow.keras.autolog()\n",
    "\n",
    "max_words = 1000\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "print(\"Loading data...\")\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(\n",
    "    num_words=max_words, test_split=0.2\n",
    ")\n",
    "\n",
    "print(len(x_train), \"train sequences\")\n",
    "print(len(x_test), \"test sequences\")\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, \"classes\")\n",
    "\n",
    "print(\"Vectorizing sequence data...\")\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode=\"binary\")\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode=\"binary\")\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "\n",
    "print(\n",
    "    \"Convert class vector to binary class matrix \"\n",
    "    \"(for use with categorical_crossentropy)\"\n",
    ")\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "print(\"Building model...\")\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_split=0.1,\n",
    ")\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "\n",
    "mlflow.keras.log_model(model, \"model\", registered_model_name=\"Test Model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVz6748M6R8_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
