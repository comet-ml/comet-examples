{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.comet.ml/img/notebook_logo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAAA3FjCZ89T"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "[Gradio](https://www.gradio.app/) allows you to quickly create customizable UI components around your TensorFlow or PyTorch models, or even arbitrary Python functions. Mix and match components to support any combination of inputs and outputs. Our core library is free and open-source!\n",
    "\n",
    "[Comet](https://www.comet.ml/site/data-scientists/?utm_campaign=gradio-integration&utm_medium=colab) is an MLOps Platform that is designed to help Data Scientists and Teams build better models faster! Comet provides tooling to track, Explain, Manage, and Monitor your models in a single place! It works with Jupyter Notebooks and Scripts and most importantly it's 100% free!\n",
    "\n",
    "In this notebook, we will go over a few of the User Interfaces you can create for your models with Gradio and how to log them to Comet and view them with the Gradio Panel.          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uWgK7xMFiPa"
   },
   "source": [
    "# Setup\n",
    "\n",
    "This integration enables you to access and interact with your Gradio Interface from within Comet.\n",
    "\n",
    "To do so, search for “Gradio” in the Public section of the Comet Panels Gallery. Add it to your project or experiment, and run any of the example snippets below to get started.\n",
    "\n",
    "**Note:** Your UI's will expire after 24 hours if you are not using a hosted version of Gradio. Find out more about hosting your UI's [here](https://www.gradio.app/sharing_your_app/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbsz-vYaFkcQ"
   },
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_102IXZDxof0"
   },
   "outputs": [],
   "source": [
    "%pip install -U comet_ml gradio altair torch torchvision transformers requests Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rsgj7AoYYCDD"
   },
   "source": [
    "## Initialize Comet and Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TB3S3RKDuEC"
   },
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "import gradio as gr\n",
    "\n",
    "comet_ml.init(project_name=\"comet-example-gradio-notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4RlXt4rWe98"
   },
   "source": [
    "# Interfaces for Image Models\n",
    "\n",
    "Lets set up a some interfaces to test out Image Classification. \n",
    "\n",
    "After running the example, you will see a link to a Comet Experiment with the logged UI. If you head over to the Panels tab in the Experiment, you will a Gradio Panel that you can use to view the UI.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojvAiC0-FD2B"
   },
   "source": [
    "## Image Classification \n",
    "\n",
    "In this example, we will build an interface to interact with an image classification model `resnet18`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YCUc1pqJE6hl"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "torch.hub.download_url_to_file(\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "\n",
    "model = torch.hub.load(\"pytorch/vision:v0.6.0\", \"resnet18\", pretrained=True).eval()\n",
    "\n",
    "# Download human-readable labels for ImageNet.\n",
    "response = requests.get(\"https://git.io/JJkYN\")\n",
    "labels = response.text.split(\"\\n\")\n",
    "\n",
    "\n",
    "def predict(inp):\n",
    "    inp = Image.fromarray(inp.astype(\"uint8\"), \"RGB\")\n",
    "    inp = transforms.ToTensor()(inp).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)\n",
    "    return {labels[i]: float(prediction[i]) for i in range(1000)}\n",
    "\n",
    "\n",
    "inputs = gr.Image()\n",
    "outputs = gr.Label(num_top_classes=3)\n",
    "\n",
    "io = gr.Interface(\n",
    "    fn=predict, inputs=inputs, outputs=outputs, examples=[\"dog.jpg\"]\n",
    ")\n",
    "io.launch(inline=False, share=True)\n",
    "\n",
    "experiment = comet_ml.Experiment()\n",
    "experiment.add_tag(\"image-classifier\")\n",
    "\n",
    "io.integrate(comet_ml=experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCmeuULcUSbt"
   },
   "source": [
    "# Interfaces for NLP Models\n",
    "\n",
    "Lets build some interfaces to interact with Transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksLtgWPfQZFL"
   },
   "source": [
    "## Text Generation\n",
    "\n",
    "In this example we will build a UI around GPT2 to generate a story. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYmq8tV-Pz-Z"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "MODEL_NAME = \"gpt2\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# set model decoder to true\n",
    "model.config.is_decoder = True\n",
    "# set text-generation params under task_specific_params\n",
    "model.config.task_specific_params[\"text-generation\"] = {\n",
    "    \"do_sample\": True,\n",
    "    \"max_length\": 50,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_k\": 50,\n",
    "    \"no_repeat_ngram_size\": 2\n",
    "}\n",
    "model = model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "def generate_text(inp):\n",
    "    input_ids = tokenizer.encode(inp, return_tensors=\"pt\")\n",
    "    beam_output = model.generate(\n",
    "        input_ids.to(device),\n",
    "        max_length=100,\n",
    "        num_beams=5,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "    output = tokenizer.decode(\n",
    "        beam_output[0], skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )\n",
    "    return \".\".join(output.split(\".\")[:-1]) + \".\"\n",
    "\n",
    "input_text = gr.Textbox(label=\"Input Prompt\")\n",
    "output_text = gr.Textbox(label=\"Generated Output\")\n",
    "io = gr.Interface(\n",
    "    generate_text,\n",
    "    inputs=input_text,\n",
    "    outputs=output_text,\n",
    "    examples=[\n",
    "        [\n",
    "            \"The dectective looked at the room full of suspects and said, \"\n",
    "        ]\n",
    "    ],\n",
    ")\n",
    "io.launch(inline=False, share=True)\n",
    "\n",
    "experiment = comet_ml.Experiment()\n",
    "experiment.add_tag(\"text-generation\")\n",
    "\n",
    "io.integrate(comet_ml=experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcYI1Di2RiJ_"
   },
   "source": [
    "## Question Answering\n",
    "\n",
    "Let's build a UI for question answering with DistilBert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6sFy40JYRLyC"
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "do_lower_case = True\n",
    "model_version = \"distilbert-base-uncased-distilled-squad\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_version, do_lower_case=do_lower_case\n",
    ")\n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    model_version, output_attentions=True, pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "qa = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "\n",
    "def qa_func(context, question):\n",
    "    prediction = qa(question=question, context=context)\n",
    "    answer = prediction['answer']\n",
    "\n",
    "    return answer\n",
    "\n",
    "io = gr.Interface(\n",
    "    qa_func,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=7, label=\"Context\"),\n",
    "        gr.Textbox(label=\"Question\"),\n",
    "    ],\n",
    "    outputs=[gr.Textbox(label=\"Answer\")],\n",
    "    examples=[[\"\"\"A Moon landing is the arrival of a spacecraft on the surface of the Moon.\n",
    "    This includes both crewed and robotic missions. The first human-made object to touch the Moon was the Soviet Union's Luna 2, on 13 September 1959.\n",
    "    The United States' Apollo 11 was the first crewed mission to land on the Moon, on 20 July 1969. \n",
    "    There were six crewed U.S. landings between 1969 and 1972, and numerous uncrewed landings, with no soft landings happening between 22 August 1976 and 14 December 2013.\n",
    "    \"\"\", \"What year did the first crewed mission land on the moon?\"]\n",
    "    ]\n",
    ")\n",
    "io.launch(inline=False, share=True)\n",
    "\n",
    "experiment = comet_ml.Experiment()\n",
    "experiment.add_tag(\"question-answering\")\n",
    "\n",
    "io.integrate(comet_ml=experiment)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "tAAA3FjCZ89T"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4 (default, Apr 20 2021, 09:36:35) \n[Clang 9.1.0 (clang-902.0.39.2)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
