{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.comet.ml/img/notebook_logo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Comet](https://www.comet.com/site/products/ml-experiment-tracking/?utm_campaign=ray_train&utm_medium=colab) is an MLOps Platform that is designed to help Data Scientists and Teams build better models faster! Comet provides tooling to track, Explain, Manage, and Monitor your models in a single place! It works with Jupyter Notebooks and Scripts and most importantly it's 100% free to get started!\n",
    "\n",
    "[Ray Train](https://docs.ray.io/en/latest/train/train.html) abstracts away the complexity of setting up a distributed training system.\n",
    "\n",
    "Instrument your runs with Comet to start managing experiments, create dataset versions and track hyperparameters for faster and easier reproducibility and collaboration.\n",
    "\n",
    "[Find more information about our integration with Ray Train](https://www.comet.com/docs/v2/integrations/ml-frameworks/ray/)\n",
    "\n",
    "Get a preview for what's to come. Check out a completed experiment created from this notebook [here](https://www.comet.com/examples/comet-example-ray-train-keras/99d169308c854be7ac222c995a2bfa26?experiment-tab=systemMetrics).\n",
    "\n",
    "This example is based on the [following Ray Train Tensorflow example](https://docs.ray.io/en/latest/train/examples/tf/tensorflow_mnist_example.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYchV5RWwdv5"
   },
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJnmqphuY2eI"
   },
   "outputs": [],
   "source": [
    "%pip install -U \"comet_ml>=3.44.0\" \"ray[air]>=2.1.0\" \"keras<3\" \"tensorflow<2.16.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crOcPHobwhGL"
   },
   "source": [
    "# Login to Comet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNQRM0U3caiY"
   },
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "\n",
    "comet_ml.login(project_name=\"comet-example-ray-train-keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgqwGSwtzVWD"
   },
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-5rRYaUw5AF"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import comet_ml.integration.ray\n",
    "\n",
    "import numpy as np\n",
    "import ray\n",
    "from ray.air.config import RunConfig, ScalingConfig\n",
    "from ray.air.result import Result\n",
    "from ray.train.tensorflow import TensorflowTrainer\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_dataset(batch_size: int) -> tf.data.Dataset:\n",
    "    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "    # The `x` arrays are in uint8 and have values in the [0, 255] range.\n",
    "    # You need to convert them to float32 with values in the [0, 1] range.\n",
    "    x_train = x_train / np.float32(255)\n",
    "    y_train = y_train.astype(np.int64)\n",
    "    train_dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "        .shuffle(60000)\n",
    "        .repeat()\n",
    "        .batch(batch_size)\n",
    "    )\n",
    "    return train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model() -> tf.keras.Model:\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(28, 28)),\n",
    "            tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJuThf1TxP_G"
   },
   "source": [
    "# Define your distributed training function\n",
    "\n",
    "This function is gonna be distributed and executed on each distributed worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFbozHiJxTax"
   },
   "outputs": [],
   "source": [
    "def train_func(config: dict):\n",
    "    from comet_ml.integration.ray import comet_worker_logger\n",
    "    from ray.air import session\n",
    "\n",
    "    per_worker_batch_size = config.get(\"batch_size\", 64)\n",
    "    epochs = config.get(\"epochs\", 3)\n",
    "    steps_per_epoch = config.get(\"steps_per_epoch\", 70)\n",
    "\n",
    "    with comet_worker_logger(config) as experiment:\n",
    "\n",
    "        tf_config = json.loads(os.environ[\"TF_CONFIG\"])\n",
    "        num_workers = len(tf_config[\"cluster\"][\"worker\"])\n",
    "\n",
    "        strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "\n",
    "        global_batch_size = per_worker_batch_size * num_workers\n",
    "        multi_worker_dataset = mnist_dataset(global_batch_size)\n",
    "\n",
    "        with strategy.scope():\n",
    "            # Model building/compiling need to be within `strategy.scope()`.\n",
    "            multi_worker_model = build_cnn_model()\n",
    "            learning_rate = config.get(\"lr\", 0.001)\n",
    "            multi_worker_model.compile(\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "                metrics=[\"accuracy\"],\n",
    "            )\n",
    "\n",
    "        callbacks = []\n",
    "        if session.get_world_rank() == 0:\n",
    "            callbacks.append(experiment.get_callback(\"tf-keras\"))\n",
    "\n",
    "        history = multi_worker_model.fit(\n",
    "            multi_worker_dataset,\n",
    "            epochs=epochs,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "        results = history.history\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the function that schedule the distributed job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tensorflow_mnist(\n",
    "    num_workers: int = 2, use_gpu: bool = False, epochs: int = 4\n",
    ") -> Result:\n",
    "    config = {\"lr\": 1e-3, \"batch_size\": 64, \"epochs\": epochs}\n",
    "\n",
    "    callback = comet_ml.integration.ray.CometTrainLoggerCallback(config)\n",
    "\n",
    "    trainer = TensorflowTrainer(\n",
    "        train_loop_per_worker=train_func,\n",
    "        train_loop_config=config,\n",
    "        scaling_config=ScalingConfig(num_workers=num_workers, use_gpu=use_gpu),\n",
    "        run_config=RunConfig(callbacks=[callback]),\n",
    "    )\n",
    "    results = trainer.fit()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "Ray will wait indefinitely if we request more num_workers that the available resources, the code below ensure we never request more CPU than available locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_num_workers = 2\n",
    "\n",
    "available_local_cpu_count = os.cpu_count() - 1\n",
    "num_workers = min(ideal_num_workers, available_local_cpu_count)\n",
    "\n",
    "if num_workers < 1:\n",
    "    num_workers = 1\n",
    "\n",
    "train_tensorflow_mnist(num_workers, use_gpu=False, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
